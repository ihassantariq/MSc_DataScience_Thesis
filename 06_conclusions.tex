\chapter{Conclusions} \label{chap6}

\section{Summary} \label{6summary}

In the end, the categorization of 12-channel ECG arrhythmias was improved by using oversampling (and undersampling) approaches. Random Oversampling (ROS), in particular, performed admirably. The latter showed a considerable increment compared to the model trained with the original data. Although SMOTE performed well in a variety of cases, ROS was chosen as the best strategy due to its ease of implementation.

In conclusion, Catboost with the random oversampling technique was the best model but we cannot deploy that in mobile devices which support both Android/IOS as well as the XGBoost ROS model. DNN ROS, LSTM and Team \# 20 model can be deployed to mobile devices easily and perform better with the same accuracy and F1-Score. Any model that is built using Matlab Keras library, Pytorch framework Keras library and Tensorflow Keras library and Tensorflow itself can be converted to Tensorflow Lite and we can see them in action in the above demo \ref{modelsdeployment}. Inferencing big models like Team \#2 and Team \# 20 models takes a lot of time to get the output after conversion. 

As far as Federated Learning is concerned, the DNN trained with ROS (oversampled) data proved to be the best model in the setting of FL. The latter had an Overall Index of 0.55 and an F1-Score of 0.55. Even said, when more than four local nodes were included, utilizing an LSTM with oversampled data produced more consistent results. Then LSTM is the recommended model to implement within this data when the number of nodes is large. On the other hand, DNN with ROS data is the candidate to select when dealing with a small number of clients.



\section{Future Developments} \label{6futuredevelopments}

In terms of future work, converting the competence team \# 20 model to utilize it directly in a mobile application can be done easily because it's already converted to Tensorflow Lite. Also, training models of Catboost, XGBoost, competence team \# 2 and competence team \# 20 in FL settings can be done and looking at their overall index can be good insight for future work. In the end, as we deployed the models in mobile as edge nodes, these can also be deployed to Arduino by utilizing Tensorflow quantization techniques and training them directly in edge devices instead of simulating its behaviour to see how they perform in real settings could be something that requires more resources and can be benefiting in real world performance analysis of these models. Also, after central training, we can utilize transfer learning technique in a federated learning environment where a model has been trained already and it will get trained over a new dataset without sharing patients data keeping in mind privacy concerns.  

